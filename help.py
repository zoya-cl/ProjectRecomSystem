# -*- coding: utf-8 -*-
"""Recommendation_TFIDF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14hFt9l2Mk5MhGShdWOh0SHub-nKnpIvC
"""

import os
import pandas as pd
import numpy as np

# Define the file path for the Excel file
file_path = '/content/Project Repo CL.xlsx' # Changed from .csv to .xlsx

df_projects = None # Initialize df_projects to None

# Check if the file exists
if os.path.exists(file_path):
    print(f"File '{file_path}' found. Attempting to load dataset...")
    try:

        df_projects = pd.read_excel(file_path)
        print("Dataset loaded successfully.")

        # Display the first few rows of the DataFrame
        print("\nFirst 5 rows of the DataFrame:")
        print(df_projects.head())

        # Print the column names to verify the presence of key variables
        print("\nColumn names in the DataFrame:")
        print(df_projects.columns.tolist())

        # Display concise summary of the DataFrame to check data types and non-null values
        print("\nDataFrame Info:")
        df_projects.info()

    except Exception as e:
        print(f"Error loading dataset: {e}")
        print("Please ensure the file is a valid Excel file and not corrupted.")
else:
    print(f"Error: '{file_path}' not found.")
    print("Please ensure the Excel file is uploaded to the current environment or update the 'file_path' variable with the correct absolute or relative path to the 'projects_data.xlsx' file.")

sheet_name = 'Master Sheet'

try:
    df_projects = pd.read_excel(file_path, sheet_name=sheet_name)
    print(f"Successfully loaded '{sheet_name}' from '{file_path}'.")

    # Display the first few rows of the DataFrame
    print(f"\nFirst 5 rows of the '{sheet_name}' DataFrame:")
    print(df_projects.head())

    # Print the column names
    print(f"\nColumn names in the '{sheet_name}' DataFrame:")
    print(df_projects.columns.tolist())

    # Display concise summary of the DataFrame
    print(f"\nDataFrame Info for '{sheet_name}':")
    df_projects.info()

except Exception as e:
    print(f"Error loading sheet '{sheet_name}': {e}")
    print("Please ensure the sheet name is correct and the file is accessible.")

columns_to_drop = [
     'Unnamed: 10',
    'Unnamed: 11',
    'Unnamed: 19',
    'Unnamed: 20',
    'Unnamed: 21',
    'Unnamed: 22',
    'Unnamed: 23',
     'Project ID.1',
     'Documentation',
    'Thumbnail',
    'Instructional Video'
]

df_projects = df_projects.drop(columns=columns_to_drop, errors='ignore')

print("Columns dropped successfully. Current columns in DataFrame are:")
print(df_projects.columns.tolist())
print("\nFirst 5 rows of the updated DataFrame:")
print(df_projects.head())

# Step 1: Create a dictionary for specific replacements (remove #)
special_replacements = {
    "Title#1": "Title1",
    "Title #2": "Title2",
    "Usecase #1": "Usecase1",
    "Usecase #2": "Usecase2",
    "Usecase #3": "Usecase3"
}

# Step 2: Apply the above renames first
df_projects = df_projects.rename(columns=special_replacements)

# Step 3: Remove spaces from all columns
df_projects.columns = df_projects.columns.str.replace(" ", "")

# Preview
print(df_projects.columns)

df_projects.head()

df_projects = df_projects.rename(columns={'Domain.1': 'SubDomain'})
df_projects.head()

import ast

def convert(text):
    L = []
    for i in ast.literal_eval(text):
        L.append(i['name'])
    return L

import ast

# Columns to clean
columns_to_clean = ['SubDomain', 'LanguageUsed', 'Toolkits/Libraries', 'Keywords']
print(f"\nCleaning columns {columns_to_clean} (handling nested lists):")

def clean_nested_list_cell(x):
    """
    Converts strange data like:
    - [["'A'", "'B'"]]
    - [['A', 'B']]
    - "['A','B']"
    - A list with one nested list
    into: ['A', 'B']
    """
    # Already a list
    if isinstance(x, list):
        # flatten if nested like [['A','B']]
        if len(x) == 1 and isinstance(x[0], list):
            return [item.strip().strip("'").strip('"') for item in x[0]]
        else:
            return [str(item).strip().strip("'").strip('"') for item in x]

    # If string â†’ try to parse
    try:
        obj = ast.literal_eval(str(x))
        if isinstance(obj, list):
            if len(obj) == 1 and isinstance(obj[0], list):
                return [str(item).strip().strip("'").strip('"') for item in obj[0]]
            return [str(item).strip().strip("'").strip('"') for item in obj]
    except:
        pass

    # Fallback: return single string as list
    return [str(x).strip().strip("'").strip('"')]


# Apply cleaning
for col in columns_to_clean:
    if col in df_projects.columns:
        print(f"\nProcessing column: '{col}'")
        df_projects[col] = df_projects[col].apply(clean_nested_list_cell)
        print(f"First 5 cleaned entries for '{col}':")
        print(df_projects[col].head())
    else:
        print(f"Column '{col}' does not exist. Skipping.")

print("\nDataFrame Info (selected columns):")
print(df_projects[columns_to_clean].info())

import re

def extract_time(value):
    # Convert to string
    text = str(value)

    # Find all numbers (handles "2-3", "8 Hours", "10 hour", etc.)
    nums = re.findall(r'\d+', text)

    if not nums:
        return None   # or return 0 if you prefer

    nums = list(map(int, nums))

    # If two numbers (like 2-3), return the average
    if len(nums) == 2:
        return sum(nums) / 2

    # Otherwise return the single number
    return nums[0]

# Apply to column
df_projects['ExpectedBuildTime'] = df_projects['ExpectedBuildTime'].apply(extract_time)

# Preview
print(df_projects['ExpectedBuildTime'].head())

df_projects.head()

def join_list_or_str(val):
    if isinstance(val, list):
        return " ".join(map(str, val))
    return str(val)

text_cols = [
    "TitleoftheProject",
    "Title1",
    "Title2",
    "Usecase1",
    "Usecase2",
    "Usecase3",
    "ShortDescription",
    "Domain",
    "SubDomain",
    "LanguageUsed",
    "Toolkits/Libraries",
    "Keywords",
]

df_projects["tags"] = (
    df_projects["TitleoftheProject"].astype(str) + " " +
    df_projects["Title1"].astype(str) + " " +
    df_projects["Title2"].astype(str) + " " +
    df_projects["Usecase1"].astype(str) + " " +
    df_projects["Usecase2"].astype(str) + " " +
    df_projects["Usecase3"].astype(str) + " " +
    df_projects["ShortDescription"].astype(str) + " " +
    df_projects["Domain"].astype(str) + " " +
    df_projects["SubDomain"].apply(join_list_or_str) + " " +
    df_projects["LanguageUsed"].apply(join_list_or_str) + " " +
    df_projects["Toolkits/Libraries"].apply(join_list_or_str) + " " +
    df_projects["Keywords"].apply(join_list_or_str)
)

# Normalize to lowercase
df_projects["tags"] = df_projects["tags"].str.lower()

print(df_projects[["ProjectID", "TitleoftheProject", "tags"]].head())

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(stop_words="english")
vectors = tfidf.fit_transform(df_projects["tags"])

print(vectors.shape)  # (num_projects, num_features)

from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity(vectors)

"""**Search by Title of the Project**"""

def recommend_by_title(title, top_n=5):
    # try to find the project index
    matches = df_projects[df_projects["TitleoftheProject"].str.lower() == title.lower()]
    if matches.empty:
        print(f"No project found with title: {title}")
        return

    idx = matches.index[0]

    # list of (project_index, similarity_score)
    scores = list(enumerate(similarity[idx]))

    # sort by similarity descending, skip itself (idx)
    scores = sorted(scores, key=lambda x: x[1], reverse=True)

    print(f"\nBecause you selected: {df_projects.loc[idx, 'TitleoftheProject']}")
    print("Recommended projects:\n")

    count = 0
    for i, score in scores:
        if i == idx:
            continue  # skip the same project
        print(f"- {df_projects.loc[i, 'TitleoftheProject']}  |  Domain: {df_projects.loc[i, 'Domain']}  |  Score: {score:.3f}")
        count += 1
        if count >= top_n:
            break

recommend_by_title("Molecule DJ", top_n=5)

"""**Recommendation with filters (Domain, ToughnessLevel, time)**"""

def recommend_filtered(title, top_n=5, domain=None, max_build_time=None):
    matches = df_projects[df_projects["TitleoftheProject"].str.lower() == title.lower()]
    if matches.empty:
        print(f"No project found with title: {title}")
        return

    idx = matches.index[0]
    base_domain = df_projects.loc[idx, "Domain"]

    scores = list(enumerate(similarity[idx]))
    scores = sorted(scores, key=lambda x: x[1], reverse=True)

    print(f"\nBecause you selected: {df_projects.loc[idx, 'TitleoftheProject']}")
    print(f"Filters -> Domain: {domain or 'any'}, MaxBuildTime: {max_build_time or 'any'}")
    print("Recommended projects:\n")

    count = 0
    for i, score in scores:
        if i == idx:
            continue

        # domain filter
        if domain is not None and df_projects.loc[i, "Domain"] != domain:
            continue

        # max build time filter
        if (max_build_time is not None and
            pd.notna(df_projects.loc[i, "ExpectedBuildTime"]) and
            df_projects.loc[i, "ExpectedBuildTime"] > max_build_time):
            continue

        print(f"- {df_projects.loc[i, 'TitleoftheProject']} | Domain: {df_projects.loc[i, 'Domain']} | BuildTime: {df_projects.loc[i, 'ExpectedBuildTime']} | Score: {score:.3f}")
        count += 1
        if count >= top_n:
            break

recommend_filtered("Molecule DJ", top_n=5, domain="Deep Learning", max_build_time=4)

"""**Recommend based on free-text keywords**"""

project_vectors = tfidf.fit_transform(df_projects["tags"])

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def recommend_from_keywords(query, top_n=5):
    """
    query: string, e.g. "computer vision openvino real-time anonymization"
    top_n: how many projects to return
    """
    if not query or not isinstance(query, str):
        print("Please provide a non-empty keyword string.")
        return

    # Convert query to same vector space
    query = query.lower()
    query_vec = tfidf.transform([query])          # shape: (1, num_features)

    # Compute cosine similarity with all project vectors
    sims = cosine_similarity(query_vec, project_vectors).flatten()  # shape: (num_projects,)

    # Get indices of top_n highest scores
    top_idx = np.argsort(sims)[::-1][:top_n]

    print(f"\nQuery: {query}")
    print("Top recommendations:\n")

    for idx in top_idx:
        row = df_projects.iloc[idx]
        print(f"ProjectID: {row['ProjectID']}")
        print(f"Title   : {row['TitleoftheProject']}")
        print(f"Domain  : {row['Domain']}")
        print(f"Toughness: {row['ToughnessLevel']}")
        print(f"BuildTime: {row['ExpectedBuildTime']} hours")
        print(f"Score   : {sims[idx]:.3f}")
        print("-" * 60)

recommend_from_keywords("Computer vision", top_n=5)

"""**Free Keyword search - added filters**"""

def recommend_from_keywords_filtered(query, top_n=5, domain=None, max_time=None, level=None):
    query = query.lower()
    query_vec = tfidf.transform([query])
    sims = cosine_similarity(query_vec, project_vectors).flatten()

    # Sort all indices by similarity
    sorted_idx = np.argsort(sims)[::-1]

    results = []
    for idx in sorted_idx:
        row = df_projects.iloc[idx]

        # Filters
        if domain is not None and row["Domain"] != domain:
            continue
        if max_time is not None and row["ExpectedBuildTime"] > max_time:
            continue
        if level is not None and row["ToughnessLevel"] != level:
            continue

        results.append(idx)
        if len(results) >= top_n:
            break

    print(f"\nQuery: {query}")
    print(f"Filters -> Domain: {domain or 'any'}, MaxTime: {max_time or 'any'}, Level: {level or 'any'}\n")

    for idx in results:
        row = df_projects.iloc[idx]
        print(f"ProjectID: {row['ProjectID']}")
        print(f"Title   : {row['TitleoftheProject']}")
        print(f"Domain  : {row['Domain']}")
        print(f"Toughness: {row['ToughnessLevel']}")
        print(f"BuildTime: {row['ExpectedBuildTime']} hours")
        print(f"Score   : {sims[idx]:.3f}")
        print("-" * 60)

recommend_from_keywords_filtered(
    "Te",
    top_n=3,
    domain="Software Development",
    max_time=12

)

